# -*- coding: utf-8 -*-
"""Insurance_LR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SHTzvTj9VKPqUAabO_YuXlF4nyJuNUFB

## **ML Modeling**

Importing data
"""

import pandas as pd # type: ignore
import numpy as np # type: ignore
import matplotlib.pyplot as plt # type: ignore
import seaborn as sns # type: ignore

#!gdown "https://drive.google.com/uc?id=1NBk1TFkK4NeKdodR2DxIdBp2Mk1mh4AS"

df = pd.read_csv('insurance.csv')
df.head()

from pandas.plotting import scatter_matrix # type: ignore

attributes = ['Age','Height','Weight','PremiumPrice']

scatter_matrix(df[attributes],figsize=(8,6))
plt.show()

df.shape

df.describe()

df.info()

df.isnull().sum()

# Function to calculate BMI

def calculate_bmi(height,weight):
  return weight/(height**2)

# Apply BMI calculation to DataFrame

df['BMI'] = df.apply(lambda x:calculate_bmi(x['Height'],x['Weight']),axis=1)

df.head()

correlation_matrics = df.corr()

# Plotting correlation heatmap using seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrics, annot=True, cmap='coolwarm', fmt=".2f", square=True)
plt.title('Correlation Heatmap')
plt.show()

"""Drop BMI or weight because thet are heighly correlated."""

from sklearn.preprocessing import StandardScaler # type: ignore

scale = StandardScaler()

df = pd.DataFrame(scale.fit_transform(df),columns=df.columns)
df.head()

#train_test_split

from sklearn.model_selection import train_test_split # type: ignore

X = df.drop(columns=['PremiumPrice','BMI'])
y = df['PremiumPrice']

X.shape,y.shape

Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.3,random_state=42)

Xtrain.shape,ytrain.shape

Xtest.shape, ytest.shape

"""### **Linear Regression**"""

from sklearn.linear_model import LinearRegression # type: ignore

model = LinearRegression()

model.fit(Xtrain,ytrain)

model.coef_

model.intercept_

import matplotlib.pyplot as plt # type: ignore
fig = plt.figure()
y_hat = model.predict(Xtest)
plt.scatter(y_hat,ytest)
plt.legend()
plt.show()

model.score(Xtrain,ytrain)

model.score(Xtest,ytest)

"""It is clear that there is **High Veriance** and **High Bais**.

### Model Building
"""

#!gdown "https://drive.google.com/uc?id=1NBk1TFkK4NeKdodR2DxIdBp2Mk1mh4AS"

df = pd.read_csv('insurance.csv')
df.head()

# Function to calculate BMI

def calculate_bmi(height,weight):
  return weight/(height**2)

# Apply BMI calculation to DataFrame

df['BMI'] = df.apply(lambda x:calculate_bmi(x['Height'],x['Weight']),axis=1)
df.head()

X = df.drop(columns=['PremiumPrice','BMI'])
y = df['PremiumPrice']

X.shape,y.shape

# Split the data into training and testing sets
from sklearn.model_selection import train_test_split # type: ignore

X_tr_cv,X_test,y_tr_cv,y_test = train_test_split(X,y,test_size=0.15,random_state=42)
X_train,X_val,y_train,y_val = train_test_split(X_tr_cv,y_tr_cv,test_size=0.17,random_state=42)

"""### **StandardScaler**"""

from sklearn.preprocessing import StandardScaler # type: ignore

scale = StandardScaler()

X_train_scaled = scale.fit_transform(X_train)
X_test_scaled = scale.transform(X_test)

X_train.shape,y_train.shape

X_val.shape,y_val.shape

X_test.shape,y_test.shape

"""## KFold CrossValidation"""

from sklearn.model_selection import KFold,cross_val_score # type: ignore
from sklearn.metrics import mean_squared_error # type: ignore

kf = KFold(n_splits=5,shuffle=True,random_state=42)

model = LinearRegression()

R2_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='r2')

# Convert to positive MSE and print mean score
print(f"R2 Score: {np.mean(R2_scores):.4f}")

from sklearn.preprocessing import StandardScaler # type: ignore

# Split the data into training and testing sets
from sklearn.model_selection import train_test_split # type: ignore

X_tr_cv,X_test,y_tr_cv,y_test = train_test_split(X,y,test_size=0.15,random_state=42)
X_train,X_val,y_train,y_val = train_test_split(X_tr_cv,y_tr_cv,test_size=0.17,random_state=42)

from math import degrees
from sklearn.preprocessing import PolynomialFeatures # type: ignore

# Transform the features into polynomial features
degree = 5
poly = PolynomialFeatures(degree=degree)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

# Standardize the polynomial features
scaler = StandardScaler()
X_train_poly_Scaled = scaler.fit_transform(X_train_poly)
X_test_poly_scaled = scaler.transform(X_test_poly)

"""Using Sklearn's Linear Regression"""

from sklearn.linear_model import LinearRegression # type: ignore

model = LinearRegression()

model.fit(X_train_poly_Scaled,y_train)

output = model.predict(X_test_poly_scaled)

from sklearn.metrics import mean_squared_error # type: ignore

print('MSE for test:', mean_squared_error(y_test, output))

output = model.predict(X_train_poly_Scaled)
print('MSE for train:', mean_squared_error(y_train, output))

"""Here we can see that our model is very under performing and it is too bad. lets try implementing Regularization.

## Regularization
"""

def adj_r2(X,y,r2_score):
  return 1-((1-r2_score)*(len(y)-1))/(len(y)-X.shape[1]-1)

from sklearn.preprocessing import PolynomialFeatures # type: ignore
from sklearn.preprocessing import StandardScaler # type: ignore
from sklearn.linear_model import Ridge # type: ignore
from sklearn.pipeline import make_pipeline # type: ignore
from sklearn.linear_model import LinearRegression # type: ignore

train_scores = []
val_scores = []
scaler = StandardScaler()

rate_list = [0.01,0.1,1,5,10]

for rate in rate_list:
  polyreg_scaled = make_pipeline(PolynomialFeatures(3),scaler,Ridge(alpha=rate))
  polyreg_scaled.fit(X_train,y_train)
  train_score = adj_r2(X_train,y_train,polyreg_scaled.score(X_train,y_train))
  val_score = adj_r2(X_val,y_val,polyreg_scaled.score(X_val,y_val))

  train_scores.append(train_score)
  val_scores.append(val_score)

plt.figure()
plt.plot(rate_list, train_scores, label="train")
plt.plot(rate_list, val_scores, label="val")
plt.legend(loc='lower right')
plt.xlabel("lambda")
plt.ylabel("adj. R-score")
plt.grid()
plt.show()

"""## PolynomialFeatures"""

from sklearn.model_selection import KFold # type: ignore
kf = KFold(n_splits=5)

degrees = 5  # Maximum polynomial degree
train_score = []
val_score = []

for i in range(1, degrees):  # Iterate through polynomial degrees 1 to 4
    fold_train_scores = []
    fold_val_scores = []

    for train_index, val_index in kf.split(X):
        X_train, X_val = X.iloc[train_index], X.iloc[val_index]
        y_train, y_val = y.iloc[train_index], y.iloc[val_index]

        # Ensure correct polynomial degree usage
        polyreg_scaled = make_pipeline(PolynomialFeatures(i), scaler, LinearRegression())
        polyreg_scaled.fit(X_train, y_train)

        # Calculate R² and adjusted R²
        r2_train = polyreg_scaled.score(X_train, y_train)
        r2_val = polyreg_scaled.score(X_val, y_val)

        print(f"Degree: {i}, Fold Train R2: {r2_train}, Fold Val R2: {r2_val}")

        train_adj_r2 = adj_r2(X_train, y_train, r2_train)
        val_adj_r2 = adj_r2(X_val, y_val, r2_val)

        fold_train_scores.append(train_adj_r2)
        fold_val_scores.append(val_adj_r2)

    # Store mean scores across all folds
    train_score.append(np.mean(fold_train_scores))
    val_score.append(np.mean(fold_val_scores))

print(f'Mean_fold_train_scores: {train_score}')
print(f'Mean_fold_val_scores: {val_score}')

"""From the above score we can see that score is decent till **degree-2** as the **degree increased** the score is bad."""

degrees = 3  # Maximum polynomial degree
train_score = []
val_score = []

for i in range(1, degrees):  # Iterate through polynomial degrees 1 to 4
    fold_train_scores = []
    fold_val_scores = []

    for train_index, val_index in kf.split(X):
        X_train, X_val = X.iloc[train_index], X.iloc[val_index]
        y_train, y_val = y.iloc[train_index], y.iloc[val_index]

        # Ensure correct polynomial degree usage
        polyreg_scaled = make_pipeline(PolynomialFeatures(i), scaler, LinearRegression())
        polyreg_scaled.fit(X_train, y_train)

        # Calculate R² and adjusted R²
        r2_train = polyreg_scaled.score(X_train, y_train)
        r2_val = polyreg_scaled.score(X_val, y_val)

        print(f"Degree: {i}, Fold Train R2: {r2_train}, Fold Val R2: {r2_val}")

        train_adj_r2 = adj_r2(X_train, y_train, r2_train)
        val_adj_r2 = adj_r2(X_val, y_val, r2_val)

        fold_train_scores.append(train_adj_r2)
        fold_val_scores.append(val_adj_r2)

    # Store mean scores across all folds
    train_score.append(np.mean(fold_train_scores))
    val_score.append(np.mean(fold_val_scores))

print(f'Mean_fold_train_scores: {train_score}')
print(f'Mean_fold_val_scores: {val_score}')

"""It is clear that, implementing **polynomial Feature** and **LinearRegression** have improved lil bit.

# **Now lets check implementing Tree-based Models.**
"""

from sklearn.model_selection import train_test_split, KFold, cross_val_score # type: ignore
from sklearn.ensemble import GradientBoostingRegressor # type: ignore
from sklearn.preprocessing import StandardScaler # type: ignore
#from sklearn.pipeline import make_pipeline

#!gdown "https://drive.google.com/uc?id=1NBk1TFkK4NeKdodR2DxIdBp2Mk1mh4AS"

df = pd.read_csv('insurance.csv')
df.head()

# Split into train and test (90-10 split for small data)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import GradientBoostingRegressor # type: ignore

model = GradientBoostingRegressor(n_estimators=30,learning_rate=0.15,loss='squared_error',random_state=42)

# Train the model on the full training set and evaluate on the test set
model.fit(X_train, y_train)

feature_importances = model.feature_importances_
feature_importances

feature_names = X.columns

importance_df = pd.DataFrame({'Features':feature_names,'Importance':feature_importances})
importance_df

importance_df = importance_df.sort_values(by='Importance',ascending=False)

#Plot feature importance

plt.figure(figsize=(6,5))
sns.barplot(x='Features',y='Importance',data=importance_df,palette='viridis')
plt.title('Feature Importance - Gradient Boosting Regressor')
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.xticks(rotation=90)  # Rotate feature names if needed
plt.show()

"""We can see feature importance is very high for **Age**."""

test_score = model.score(X_test, y_test)

print("Final Test Score:", round(test_score,2))

"""### **Inference**

1️⃣ The Final Test Score is 0.8555, indicating that the model explains ~85.55% of the variance in the target variable.

2️⃣ This suggests that the Gradient Boosting Regressor (GBR) is performing well on unseen test data.

3️⃣ There may still be room for improvement through hyperparameter tuning or feature engineering.

4️⃣ Further analysis (e.g., residual plots, SHAP values) can help understand model behavior and potential biases.
"""

y_hat = model.predict(X_test)
y_hat

np.array(y_test)

# Get predictions
y_hat = model.predict(X_test)

# Create scatter plot
plt.figure(figsize=(8,6))
sns.scatterplot(x=y_test, y=y_hat, alpha=0.6, edgecolor='k', color='royalblue')

# Add perfect prediction line (y = x)
min_val = min(min(y_test), min(y_hat))
max_val = max(max(y_test), max(y_hat))
plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label="Perfect Prediction")

# Improve plot aesthetics
plt.xlabel("Actual Values", fontsize=12)
plt.ylabel("Predicted Values", fontsize=12)
plt.title("Actual vs Predicted Values", fontsize=14)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.show()

# Define features to drop (least important)
drop_features = ['Diabetes', 'KnownAllergies', 'BloodPressureProblems']

# Remove least important features from dataset
X_reduced = X.drop(columns=drop_features)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)

# Create a pipeline with StandardScaler and GradientBoostingRegressor
gbr = GradientBoostingRegressor(n_estimators=30,learning_rate=0.15,loss='squared_error',random_state=42)

# Train the model
gbr.fit(X_train, y_train)

# Final Test Score
test_score = gbr.score(X_test, y_test)
print("Final Test Score (After Feature Selection):", round(test_score,2))

# Get predictions
y_hat = gbr.predict(X_test)

# Create scatter plot
plt.figure(figsize=(8,6))
sns.scatterplot(x=y_test, y=y_hat, alpha=0.6, edgecolor='k', color='royalblue')

# Add perfect prediction line (y = x)
min_val = min(min(y_test), min(y_hat))
max_val = max(max(y_test), max(y_hat))
plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label="Perfect Prediction")

# Improve plot aesthetics
plt.xlabel("Actual Values", fontsize=12)
plt.ylabel("Predicted Values", fontsize=12)
plt.title("Actual vs Predicted Values", fontsize=14)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.show()


print("Final Test Score (After Feature Selection):", round(test_score,2))

"""After removing the **least important features**, the model's accuracy improved from **~87%** to **~88%**, reflecting a **1% increase in performance**. This suggests that eliminating irrelevant or low-impact features helped the model **focus** on **the most predictive variables**, reducing noise and improving generalization.

# **Inference**



*   Model Performance Analysis (Linear Regression)

   * We implemented a **Linear Regression model**, achieving a performance
score of approximately **70%**. This indicates that our model explains **70%** of the variance in the target variable based on the given features.
*   We implemented **Polynomial Features (degree = 2)** to capture non-linear relationships. However, the model exhibits both high bias and high variance, leading to **poor performance**. This suggests that the **polynomial transformation** did not generalize well, likely due to **overfitting or an inadequate fit to the data**.
*  Tree-based Models (GradientBoostingRegressor)
    *  We implemented **Gradient Boosting Regressor (GBR)**, and the model demonstrated a significant improvement in performance, achieving an accuracy of **87%**. This is a substantial enhancement compared to previous models, indicating that **GBR effectively captures** complex relationships in the data.
"""

import pickle

# Define file path
model_filename = "Insurance_PremiumPrice.pkl"

# Save the trained model
with open(model_filename, 'wb') as f:
    pickle.dump(gbr, f)

print("Model saved successfully!")

# Load the model back
with open(model_filename, 'rb') as f:
    loaded_gbr = pickle.load(f)

print("Model loaded successfully!")

